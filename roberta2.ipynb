{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import emoji as em\n",
    "import torch\n",
    "import tqdm\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "from spacy.lang.en import English\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AdamW, get_linear_schedule_with_warmup, AutoModelForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3Yah4yid5ZNf",
    "execution": {
     "iopub.status.busy": "2022-05-16T18:23:47.438862Z",
     "iopub.execute_input": "2022-05-16T18:23:47.439128Z",
     "iopub.status.idle": "2022-05-16T18:23:47.446271Z",
     "shell.execute_reply.started": "2022-05-16T18:23:47.439098Z",
     "shell.execute_reply": "2022-05-16T18:23:47.445447Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "FBlEZ-M65ZNh",
    "outputId": "eb04c62e-48be-4563-da98-7bfb248acd4a",
    "execution": {
     "iopub.status.busy": "2022-05-16T18:23:51.581930Z",
     "iopub.execute_input": "2022-05-16T18:23:51.582198Z",
     "iopub.status.idle": "2022-05-16T18:23:51.589200Z",
     "shell.execute_reply.started": "2022-05-16T18:23:51.582169Z",
     "shell.execute_reply": "2022-05-16T18:23:51.588420Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset_path = \"/content/drive/MyDrive/dataset/SemEval2018-T3-train-taskA_emoji.txt\"\n",
    "test_dataset_path = \"/content/drive/MyDrive/dataset/SemEval2018-T3_gold_test_taskA_emoji.txt\"\n",
    "smileys_path  = \"/content/drive/MyDrive/dataset/emoticons.json\""
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "6ysSwwSD5ZNi",
    "execution": {
     "iopub.status.busy": "2022-05-16T18:23:55.227446Z",
     "iopub.execute_input": "2022-05-16T18:23:55.228162Z",
     "iopub.status.idle": "2022-05-16T18:23:55.233333Z",
     "shell.execute_reply.started": "2022-05-16T18:23:55.228122Z",
     "shell.execute_reply": "2022-05-16T18:23:55.232610Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(train_dataset_path, sep=\"\\t\")\n",
    "train_df.rename(columns={\"Tweet index\": \"index\", \"Label\": \"label\", \"Tweet text\": \"text\"},\n",
    "                inplace=True)\n",
    "\n",
    "test_df = pd.read_csv(train_dataset_path, sep=\"\\t\")\n",
    "test_df.rename(columns={\"Tweet index\": \"index\", \"Label\": \"label\", \"Tweet text\": \"text\"},\n",
    "               inplace=True)\n",
    "test_df.head()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "h2AWdirk5ZNj",
    "outputId": "f0763a82-e776-4819-aabf-4edde1422ba6",
    "execution": {
     "iopub.status.busy": "2022-05-16T18:23:58.835311Z",
     "iopub.execute_input": "2022-05-16T18:23:58.835869Z",
     "iopub.status.idle": "2022-05-16T18:23:58.873710Z",
     "shell.execute_reply.started": "2022-05-16T18:23:58.835833Z",
     "shell.execute_reply": "2022-05-16T18:23:58.873001Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   index  label                                               text\n0      1      1  Sweet United Nations video. Just in time for C...\n1      2      1  @mrdahl87 We are rumored to have talked to Erv...\n2      3      1  Hey there! Nice to see you Minnesota/ND Winter...\n3      4      0                3 episodes left I'm dying over here\n4      5      1  I can't breathe! was chosen as the most notabl...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Sweet United Nations video. Just in time for C...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>3 episodes left I'm dying over here</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>I can't breathe! was chosen as the most notabl...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "train_df[\"length\"] = train_df[\"text\"].apply(lambda x: len(x.split()))\n",
    "sns.histplot(train_df[\"length\"])\n",
    "plt.title(\"Frequency of documents of a given length\", fontsize=14)\n",
    "plt.xlabel(\"length\", fontsize=14)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SmnMPiKu5ZNk",
    "outputId": "1eb39b55-6cc1-44be-bd15-56bafaaef7e9",
    "execution": {
     "iopub.status.busy": "2022-05-16T18:11:06.042239Z",
     "iopub.execute_input": "2022-05-16T18:11:06.042532Z",
     "iopub.status.idle": "2022-05-16T18:11:06.526621Z",
     "shell.execute_reply.started": "2022-05-16T18:11:06.042496Z",
     "shell.execute_reply": "2022-05-16T18:11:06.525953Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'length')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_dict(filepath):\n",
    "    \"\"\"Loads dict from json file\"\"\"\n",
    "    file = open(filepath, \"r\", encoding=\"utf8\")\n",
    "    loaded_dict = file.read()\n",
    "    return json.loads(loaded_dict)\n",
    "\n",
    "tokenizer = Tokenizer(English().vocab)\n",
    "smiley_dict = load_dict(smileys_path)\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    l = tokenizer(text)\n",
    "    for t_n in l:\n",
    "        t = t_n.text\n",
    "        if '@' in t and len(t) > 1:\n",
    "            t = '@user'\n",
    "        elif 'http' in t.lower():\n",
    "            t = 'http'\n",
    "        elif t in smiley_dict:\n",
    "            t = smiley_dict[t]\n",
    "        t = em.demojize(t, delimiters=(\"\", \"\"))\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"text\"] = train_df[\"text\"].apply(lambda x: preprocess(x))\n",
    "test_df[\"text\"] = test_df[\"text\"].apply(lambda x: preprocess(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class SarcasticSentenceDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len=128):\n",
    "        if len(sentences) != len(labels):\n",
    "            raise ValueError(\"Sentences and labels should have the same number of elements.\")\n",
    "\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        inputs = self.tokenizer(self.sentences[index],\n",
    "                                truncation=True,\n",
    "                                pad_to_max_length=True,\n",
    "                                return_tensors=\"pt\",\n",
    "                                max_length=self.max_len)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "pX1Aebmv5ZNl",
    "outputId": "1223f860-46cc-4035-9042-b7a73be9c877",
    "execution": {
     "iopub.status.busy": "2022-05-16T18:24:16.818840Z",
     "iopub.execute_input": "2022-05-16T18:24:16.819493Z",
     "iopub.status.idle": "2022-05-16T18:24:16.829598Z",
     "shell.execute_reply.started": "2022-05-16T18:24:16.819436Z",
     "shell.execute_reply": "2022-05-16T18:24:16.828848Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "train_dataset = SarcasticSentenceDataset(sentences=train_df[\"text\"].tolist(),\n",
    "                                         labels=train_df[\"label\"].tolist(),\n",
    "                                         tokenizer=tokenizer)\n",
    "\n",
    "test_dataset = SarcasticSentenceDataset(sentences=test_df[\"text\"].tolist(),\n",
    "                                        labels=test_df[\"label\"].tolist(),\n",
    "                                        tokenizer=tokenizer)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "VKdFTlFb5ZNm",
    "execution": {
     "iopub.status.busy": "2022-05-16T18:24:23.059920Z",
     "iopub.execute_input": "2022-05-16T18:24:23.060181Z",
     "iopub.status.idle": "2022-05-16T18:24:26.558546Z",
     "shell.execute_reply.started": "2022-05-16T18:24:23.060153Z",
     "shell.execute_reply": "2022-05-16T18:24:26.557803Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "item = train_dataset[0]\n",
    "print(f\"sentence: {train_df['text'][0]}\\n\"\n",
    "      f\"ids: {item['input_ids']}\\n\"\n",
    "      f\"attention_mask: {item['attention_mask']}\\n\"\n",
    "      f\"label: {item['labels']}\")"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "fgBzjZHr5ZNn",
    "outputId": "320663e6-3c06-4223-c209-7c7e1ae13996",
    "execution": {
     "iopub.status.busy": "2022-05-16T18:24:28.530018Z",
     "iopub.execute_input": "2022-05-16T18:24:28.530951Z",
     "iopub.status.idle": "2022-05-16T18:24:28.552884Z",
     "shell.execute_reply.started": "2022-05-16T18:24:28.530899Z",
     "shell.execute_reply": "2022-05-16T18:24:28.551241Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: Sweet United Nations video. Just in time for Christmas. #imagine #NoReligion  http://t.co/fej2v3OUBR\n",
      "ids: tensor([    0, 35942,   315,  3076,   569,     4,  1801,    11,    86,    13,\n",
      "         1619,     4,   849,   757, 37620,   849,  3084, 29806, 43617,  1437,\n",
      "         2054,   640,    90,     4,   876,    73,  7068,   267,   176,   705,\n",
      "          246,  5061,  7202,     2,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1])\n",
      "attention_mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "label: 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def train(model,\n",
    "          dataset,\n",
    "          device,\n",
    "          lr=5e-5,\n",
    "          num_epochs=5,\n",
    "          batch_size=8):\n",
    "    train_loader, validation_loader = setup_dataset_loaders(dataset, batch_size)\n",
    "\n",
    "    num_batches = len(dataset) // batch_size\n",
    "    num_warmup_steps = min(4000, int(0.1 * num_epochs * num_batches))\n",
    "    num_training_steps = num_batches * num_epochs\n",
    "    optimizer, scheduler = setup_optimizer_and_scheduler(model,\n",
    "                                                         lr,\n",
    "                                                         num_warmup_steps,\n",
    "                                                         num_training_steps)\n",
    "\n",
    "    best_f1 = 0\n",
    "    best_epoch = -1\n",
    "    best_params = copy.deepcopy(model.state_dict())\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"epoch: {epoch}\")\n",
    "\n",
    "        train_result = train_epoch(model, optimizer, scheduler, train_loader, device)\n",
    "        print(f\"train loss: {train_result['loss']}\\n\"\n",
    "              f\"train accuracy: {train_result['accuracy']}\\n\")\n",
    "\n",
    "        valid_result = valid_epoch(model, validation_loader, device)\n",
    "        print(f\"valid accuracy: {valid_result['accuracy']}\\n\"\n",
    "              f\"valid f1: {valid_result['f1']}\\n\")\n",
    "\n",
    "        if valid_result[\"f1\"] > best_f1:\n",
    "            best_f1 = valid_result[\"f1\"]\n",
    "            best_epoch = epoch\n",
    "            best_params = copy.deepcopy(model.state_dict())\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        print(f\"patience: {patience}\\n\")\n",
    "        if patience == 2:\n",
    "            break\n",
    "\n",
    "    print(f\"best epoch: {best_epoch}\\n\"\n",
    "          f\"best f1: {best_f1}\\n\")\n",
    "\n",
    "    model.load_state_dict(best_params)\n",
    "    return model\n",
    "\n",
    "\n",
    "def setup_dataset_loaders(dataset, batch_size):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(0.2 * dataset_size))\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    validation_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              sampler=train_sampler,\n",
    "                              batch_size=batch_size)\n",
    "    validation_loader = DataLoader(train_dataset,\n",
    "                                   sampler=validation_sampler,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "    return train_loader, validation_loader\n",
    "\n",
    "\n",
    "def setup_optimizer_and_scheduler(model, lr, num_warmup_steps, num_training_steps):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=num_warmup_steps,\n",
    "                                                num_training_steps=num_training_steps)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, scheduler, loader, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "    total_steps = 0\n",
    "\n",
    "    for batch in tqdm.tqdm(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        output = model(input_ids, attention_mask=mask, labels=labels, return_dict=True)\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        _, preds = torch.max(output.logits, dim=1, keepdim=False)\n",
    "        correct = (labels == preds).sum().item()\n",
    "\n",
    "        total_steps += 1\n",
    "        total_examples += input_ids.size()[0]\n",
    "        total_loss += loss.item()\n",
    "        total_correct += correct\n",
    "\n",
    "    return {\n",
    "        \"loss\": total_loss / total_steps,\n",
    "        \"accuracy\": total_correct / total_examples\n",
    "    }\n",
    "\n",
    "\n",
    "def valid_epoch(model, loader, device):\n",
    "    y_true, y_pred = test(model, loader, device)\n",
    "    return compute_metrics(y_true, y_pred)\n",
    "\n",
    "\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    labels_list = []\n",
    "    preds_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            output = model(input_ids, attention_mask=attention_mask, labels=labels, return_dict=True)\n",
    "            _, preds = torch.max(output.logits, dim=1, keepdim=False)\n",
    "\n",
    "            labels_list.extend(labels.cpu().numpy().tolist())\n",
    "            preds_list.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "    return labels_list, preds_list\n",
    "\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": confusion_matrix(y_true, y_pred)\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-05-16T18:30:10.308578Z",
     "iopub.execute_input": "2022-05-16T18:30:10.308836Z",
     "iopub.status.idle": "2022-05-16T18:30:10.331418Z",
     "shell.execute_reply.started": "2022-05-16T18:30:10.308807Z",
     "shell.execute_reply": "2022-05-16T18:30:10.330738Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/382 [00:34<1:13:38, 11.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForSequenceClassification\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroberta-base\u001B[39m\u001B[38;5;124m\"\u001B[39m, num_labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m result \u001B[38;5;241m=\u001B[39m valid_epoch(model, DataLoader(test_dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m), device)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      6\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest f1: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Input \u001B[1;32mIn [14]\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, dataset, device, lr, num_epochs, batch_size)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 55\u001B[0m     train_result \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     57\u001B[0m           \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     59\u001B[0m     valid_result \u001B[38;5;241m=\u001B[39m valid_epoch(model, validation_loader, device)\n",
      "Input \u001B[1;32mIn [14]\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[1;34m(model, optimizer, scheduler, loader, device)\u001B[0m\n\u001B[0;32m     97\u001B[0m output \u001B[38;5;241m=\u001B[39m model(ids, attention_mask\u001B[38;5;241m=\u001B[39mmask, labels\u001B[38;5;241m=\u001B[39mlabels, return_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     98\u001B[0m loss \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mloss\n\u001B[1;32m---> 99\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    101\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\Projects\\FER-TAR\\venv\\lib\\site-packages\\torch\\_tensor.py:363\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    354\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    355\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    356\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    357\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    361\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[0;32m    362\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[1;32m--> 363\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Projects\\FER-TAR\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2).to(device)\n",
    "model = train(model, train_dataset, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = valid_epoch(model, DataLoader(test_dataset, batch_size=4), device)\n",
    "print(f\"test accuracy: {result['accuracy']}\\n\"\n",
    "      f\"test f1: {result['f1']}\\n\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"model params saved\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}