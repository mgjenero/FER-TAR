{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-17T18:11:14.940288Z",
     "iopub.execute_input": "2022-05-17T18:11:14.940554Z",
     "iopub.status.idle": "2022-05-17T18:11:14.945453Z",
     "shell.execute_reply.started": "2022-05-17T18:11:14.940513Z",
     "shell.execute_reply": "2022-05-17T18:11:14.944592Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-17T18:11:17.797308Z",
     "iopub.execute_input": "2022-05-17T18:11:17.797860Z",
     "iopub.status.idle": "2022-05-17T18:11:17.804320Z",
     "shell.execute_reply.started": "2022-05-17T18:11:17.797820Z",
     "shell.execute_reply": "2022-05-17T18:11:17.803363Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-05-17T17:03:22.706948Z",
     "iopub.execute_input": "2022-05-17T17:03:22.707215Z",
     "iopub.status.idle": "2022-05-17T17:04:19.296772Z",
     "shell.execute_reply.started": "2022-05-17T17:03:22.707185Z",
     "shell.execute_reply": "2022-05-17T17:04:19.296053Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-17T18:11:29.318269Z",
     "iopub.execute_input": "2022-05-17T18:11:29.318537Z",
     "iopub.status.idle": "2022-05-17T18:12:06.813276Z",
     "shell.execute_reply.started": "2022-05-17T18:11:29.318495Z",
     "shell.execute_reply": "2022-05-17T18:12:06.812549Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)\n",
    "\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-17T18:12:18.782922Z",
     "iopub.execute_input": "2022-05-17T18:12:18.783182Z",
     "iopub.status.idle": "2022-05-17T18:12:18.852439Z",
     "shell.execute_reply.started": "2022-05-17T18:12:18.783153Z",
     "shell.execute_reply": "2022-05-17T18:12:18.851767Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-17T18:17:43.587560Z",
     "iopub.execute_input": "2022-05-17T18:17:43.588264Z",
     "iopub.status.idle": "2022-05-17T18:17:45.350093Z",
     "shell.execute_reply.started": "2022-05-17T18:17:43.588225Z",
     "shell.execute_reply": "2022-05-17T18:17:45.349383Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-17T18:17:48.869359Z",
     "iopub.execute_input": "2022-05-17T18:17:48.869856Z",
     "iopub.status.idle": "2022-05-17T18:17:48.876637Z",
     "shell.execute_reply.started": "2022-05-17T18:17:48.869814Z",
     "shell.execute_reply": "2022-05-17T18:17:48.875924Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-17T18:17:52.493500Z",
     "iopub.execute_input": "2022-05-17T18:17:52.494203Z",
     "iopub.status.idle": "2022-05-17T18:17:52.611886Z",
     "shell.execute_reply.started": "2022-05-17T18:17:52.494164Z",
     "shell.execute_reply": "2022-05-17T18:17:52.611193Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "from datasets import load_metric\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    model.eval()\n",
    "    acc_metric = load_metric(\"accuracy\")\n",
    "    f1_metric = load_metric(\"f1\")\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            acc_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "            f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    print(f1_metric.compute(average=\"macro\"), acc_metric.compute())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-17T18:12:50.094580Z",
     "iopub.execute_input": "2022-05-17T18:12:50.095384Z",
     "iopub.status.idle": "2022-05-17T18:16:30.377376Z",
     "shell.execute_reply.started": "2022-05-17T18:12:50.095335Z",
     "shell.execute_reply": "2022-05-17T18:16:30.376599Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def train(model, optimizer, lr_scheduler, train_loader, eval_loader, num_epochs):\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "        model.eval()\n",
    "        labels_list = []\n",
    "        preds_list = []\n",
    "        with torch.no_grad():\n",
    "            for batch in eval_loader:\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "                outputs = model(**batch)\n",
    "                _, preds = torch.max(outputs.logits, dim=1, keepdim=False)\n",
    "                labels_list.extend(batch[\"labels\"].cpu().numpy().tolist())\n",
    "                preds_list.extend(preds.cpu().numpy().tolist())\n",
    "                \n",
    "        metrics = compute_metrics(labels_list, preds_list)\n",
    "        print(f\"valid accuracy: {metrics['accuracy']}\\n\"\n",
    "              f\"valid f1: {metrics['f1']}\\n\")\n",
    "\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": confusion_matrix(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "train(model, optimizer, lr_scheduler, train_dataloader, eval_dataloader, num_epochs)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-17T18:24:16.255291Z",
     "iopub.execute_input": "2022-05-17T18:24:16.255573Z",
     "iopub.status.idle": "2022-05-17T18:27:52.752862Z",
     "shell.execute_reply.started": "2022-05-17T18:24:16.255535Z",
     "shell.execute_reply": "2022-05-17T18:27:52.752064Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 62,
   "outputs": []
  }
 ]
}