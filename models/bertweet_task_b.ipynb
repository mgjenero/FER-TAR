{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers"
   ],
   "metadata": {
    "id": "etk3-7gaB2HK",
    "outputId": "e9efc58e-438f-487e-ee66-97982dd8359d",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:49:40.336972Z",
     "iopub.execute_input": "2022-05-21T18:49:40.337178Z",
     "iopub.status.idle": "2022-05-21T18:49:49.168134Z",
     "shell.execute_reply.started": "2022-05-21T18:49:40.337150Z",
     "shell.execute_reply": "2022-05-21T18:49:49.167280Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler, DataLoader\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AdamW, get_scheduler, AutoModelForSequenceClassification\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "id": "DzP5MeHJCAII",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:49:49.171997Z",
     "iopub.execute_input": "2022-05-21T18:49:49.172301Z",
     "iopub.status.idle": "2022-05-21T18:49:49.178051Z",
     "shell.execute_reply.started": "2022-05-21T18:49:49.172273Z",
     "shell.execute_reply": "2022-05-21T18:49:49.177322Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "id": "qRntisqgB-jD",
    "outputId": "0046cc24-ffec-4a25-84fb-fe344a7e78dd",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:49:49.179512Z",
     "iopub.execute_input": "2022-05-21T18:49:49.180049Z",
     "iopub.status.idle": "2022-05-21T18:49:49.191002Z",
     "shell.execute_reply.started": "2022-05-21T18:49:49.180011Z",
     "shell.execute_reply": "2022-05-21T18:49:49.190276Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset_path = \"../input/semeval2018task3/SemEval2018-T3-train-taskB_emoji.txt\"\n",
    "test_dataset_path = \"../input/semeval2018task3/SemEval2018-T3_gold_test_taskB_emoji.txt\""
   ],
   "metadata": {
    "id": "g0o65_84CL1Q",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:49:49.192068Z",
     "iopub.execute_input": "2022-05-21T18:49:49.194528Z",
     "iopub.status.idle": "2022-05-21T18:49:49.199413Z",
     "shell.execute_reply.started": "2022-05-21T18:49:49.194490Z",
     "shell.execute_reply": "2022-05-21T18:49:49.198718Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(train_dataset_path, sep=\"\\t\")\n",
    "train_df.rename(columns={\"Tweet index\": \"index\", \"Label\": \"label\", \"Tweet text\": \"text\"},\n",
    "                inplace=True)\n",
    "\n",
    "test_df = pd.read_csv(test_dataset_path, sep=\"\\t\")\n",
    "test_df.rename(columns={\"Tweet index\": \"index\", \"Label\": \"label\", \"Tweet text\": \"text\"},\n",
    "               inplace=True)\n",
    "test_df.head()"
   ],
   "metadata": {
    "id": "SHdeiYH3CPzY",
    "outputId": "e2eb98d1-1eb4-4d9b-e9c1-cfed2d75fd99",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:49:49.200335Z",
     "iopub.execute_input": "2022-05-21T18:49:49.202588Z",
     "iopub.status.idle": "2022-05-21T18:49:49.249836Z",
     "shell.execute_reply.started": "2022-05-21T18:49:49.202548Z",
     "shell.execute_reply": "2022-05-21T18:49:49.249119Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SarcasticSentenceDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len=128):\n",
    "        if len(sentences) != len(labels):\n",
    "            raise ValueError(\"Sentences and labels should have the same number of elements.\")\n",
    "\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        inputs = self.tokenizer(self.sentences[index],\n",
    "                                truncation=True,\n",
    "                                pad_to_max_length=True,\n",
    "                                return_tensors=\"pt\",\n",
    "                                max_length=self.max_len)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)"
   ],
   "metadata": {
    "id": "N6NpDZwDCX36",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:49:49.250849Z",
     "iopub.execute_input": "2022-05-21T18:49:49.251378Z",
     "iopub.status.idle": "2022-05-21T18:49:49.275010Z",
     "shell.execute_reply.started": "2022-05-21T18:49:49.251341Z",
     "shell.execute_reply": "2022-05-21T18:49:49.274350Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "\n",
    "def train(model, \n",
    "          train_loader, \n",
    "          eval_loader,\n",
    "          device, \n",
    "          lr=5e-5,\n",
    "          num_epochs=5):\n",
    "        \n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    optimizer, lr_scheduler = setup_optimizer_and_scheduler(model,\n",
    "                                                         lr,\n",
    "                                                         0,\n",
    "                                                         num_training_steps)\n",
    "\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_epoch = -1\n",
    "    best_params = copy.deepcopy(model.state_dict())\n",
    "    patience = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "        metrics = evaluate(model, eval_loader, device)\n",
    "        print(f\"valid accuracy: {metrics['accuracy']}\\n\"\n",
    "              f\"valid precision: {metrics['precision']}\\n\"\n",
    "              f\"valid recall: {metrics['recall']}\\n\"\n",
    "              f\"valid f1: {metrics['f1']}\\n\")\n",
    "            \n",
    "        if metrics[\"f1\"] > best_f1:\n",
    "            best_f1 = metrics[\"f1\"]\n",
    "            best_epoch = epoch\n",
    "            best_params = copy.deepcopy(model.state_dict())\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        print(f\"patience: {patience}\\n\")\n",
    "        if patience == 3:\n",
    "            break\n",
    "        \n",
    "    print(f\"best epoch: {best_epoch}\\n\"\n",
    "          f\"best f1: {best_f1}\\n\")\n",
    "\n",
    "    model.load_state_dict(best_params)\n",
    "    return model\n",
    "\n",
    "\n",
    "def setup_optimizer_and_scheduler(model, lr, num_warmup_steps, num_training_steps):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = get_scheduler(name=\"linear\",\n",
    "                                             optimizer=optimizer,\n",
    "                                             num_warmup_steps=num_warmup_steps,\n",
    "                                             num_training_steps=num_training_steps)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "def evaluate(model, eval_loader, device):\n",
    "    model.eval()\n",
    "    labels_list = []\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            _, preds = torch.max(outputs.logits, dim=1, keepdim=False)\n",
    "            labels_list.extend(batch[\"labels\"].cpu().numpy().tolist())\n",
    "            preds_list.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "    return compute_metrics(labels_list, preds_list)\n",
    "\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": confusion_matrix(y_true, y_pred)\n",
    "    }"
   ],
   "metadata": {
    "id": "CctgAwF_Ca3P",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:52:19.141602Z",
     "iopub.execute_input": "2022-05-21T18:52:19.141857Z",
     "iopub.status.idle": "2022-05-21T18:52:19.159162Z",
     "shell.execute_reply.started": "2022-05-21T18:52:19.141831Z",
     "shell.execute_reply": "2022-05-21T18:52:19.158228Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Used for loading model and tokenizer\n",
    "model_name = \"vinai/bertweet-base\""
   ],
   "metadata": {
    "id": "Z5iST3MzCkdg",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:49:49.309279Z",
     "iopub.execute_input": "2022-05-21T18:49:49.309863Z",
     "iopub.status.idle": "2022-05-21T18:49:49.323889Z",
     "shell.execute_reply.started": "2022-05-21T18:49:49.309826Z",
     "shell.execute_reply": "2022-05-21T18:49:49.321375Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, normalization=True)\n",
    "train_dataset = SarcasticSentenceDataset(sentences=train_df[\"text\"].tolist(),\n",
    "                                         labels=train_df[\"label\"].tolist(),\n",
    "                                         tokenizer=tokenizer)\n",
    "\n",
    "test_dataset = SarcasticSentenceDataset(sentences=test_df[\"text\"].tolist(),\n",
    "                                        labels=test_df[\"label\"].tolist(),\n",
    "                                        tokenizer=tokenizer)"
   ],
   "metadata": {
    "id": "ZEZY0X4pC-a4",
    "outputId": "adecc211-2ac6-470f-b73c-1e44886af5b8",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:52:24.606645Z",
     "iopub.execute_input": "2022-05-21T18:52:24.607408Z",
     "iopub.status.idle": "2022-05-21T18:52:28.233074Z",
     "shell.execute_reply.started": "2022-05-21T18:52:24.607335Z",
     "shell.execute_reply": "2022-05-21T18:52:28.232374Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "item = train_dataset[0]\n",
    "print(f\"sentence: {train_df['text'][0]}\\n\"\n",
    "       f\"ids: {item['input_ids']}\\n\"\n",
    "       f\"attention_mask: {item['attention_mask']}\\n\"\n",
    "       f\"label: {item['labels']}\")"
   ],
   "metadata": {
    "id": "S-FnffYTDDh-",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:50:00.801068Z",
     "iopub.execute_input": "2022-05-21T18:50:00.801345Z",
     "iopub.status.idle": "2022-05-21T18:50:00.826652Z",
     "shell.execute_reply.started": "2022-05-21T18:50:00.801314Z",
     "shell.execute_reply": "2022-05-21T18:50:00.825925Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4).to(device)"
   ],
   "metadata": {
    "id": "w09PJ_ErDEoW",
    "outputId": "1ffa57eb-97c9-4b34-c38d-26471489aced",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:52:34.547880Z",
     "iopub.execute_input": "2022-05-21T18:52:34.548194Z",
     "iopub.status.idle": "2022-05-21T18:52:37.253410Z",
     "shell.execute_reply.started": "2022-05-21T18:52:34.548160Z",
     "shell.execute_reply": "2022-05-21T18:52:37.252659Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = train(model,\n",
    "              DataLoader(train_dataset, batch_size=8),\n",
    "              DataLoader(test_dataset, batch_size=8),\n",
    "              device,\n",
    "              num_epochs=10,\n",
    "              lr=5e-5)"
   ],
   "metadata": {
    "id": "CjgEYmySDHT-",
    "outputId": "8788a248-31d1-48d2-b39c-e41403b2b9d8",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T18:52:40.856081Z",
     "iopub.execute_input": "2022-05-21T18:52:40.856509Z",
     "iopub.status.idle": "2022-05-21T19:01:47.461177Z",
     "shell.execute_reply.started": "2022-05-21T18:52:40.856474Z",
     "shell.execute_reply": "2022-05-21T19:01:47.460442Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "metrics = evaluate(model, DataLoader(test_dataset, batch_size=8), device)\n",
    "print(f\"test accuracy: {metrics['accuracy']}\\n\"\n",
    "      f\"test precision: {metrics['precision']}\\n\"\n",
    "      f\"test recall: {metrics['recall']}\\n\"\n",
    "      f\"test f1: {metrics['f1']}\\n\")\n",
    "\n",
    "sns.heatmap(metrics[\"confusion_matrix\"], annot=True, cmap='Blues', fmt=\"d\")"
   ],
   "metadata": {
    "id": "jOrhnWfiDRZF",
    "outputId": "c4928600-ebe5-4559-df10-9a7f4863a316",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T19:03:00.922984Z",
     "iopub.execute_input": "2022-05-21T19:03:00.923257Z",
     "iopub.status.idle": "2022-05-21T19:03:04.803831Z",
     "shell.execute_reply.started": "2022-05-21T19:03:00.923228Z",
     "shell.execute_reply": "2022-05-21T19:03:04.803186Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers_interpret import MultiLabelClassificationExplainer\n",
    "\n",
    "cls_explainer = MultiLabelClassificationExplainer(\n",
    "    model,\n",
    "    tokenizer)\n",
    "word_attributions = cls_explainer(\"Perfect time to get really sick  ðŸ˜«ðŸ˜·\")\n",
    "cls_explainer.visualize()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-05-21T19:09:06.481994Z",
     "iopub.execute_input": "2022-05-21T19:09:06.482287Z",
     "iopub.status.idle": "2022-05-21T19:09:06.880337Z",
     "shell.execute_reply.started": "2022-05-21T19:09:06.482254Z",
     "shell.execute_reply": "2022-05-21T19:09:06.879683Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"model params saved\")"
   ],
   "metadata": {
    "id": "xLybru06DVtn",
    "outputId": "4e6a21fd-372c-4613-e27c-1afb945c11f1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}