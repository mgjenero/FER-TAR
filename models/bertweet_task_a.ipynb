{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AdamW, get_scheduler, AutoModelForSequenceClassification\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "id": "DzP5MeHJCAII",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:36:45.767663Z",
     "iopub.execute_input": "2022-05-22T20:36:45.767970Z",
     "iopub.status.idle": "2022-05-22T20:36:45.773889Z",
     "shell.execute_reply.started": "2022-05-22T20:36:45.767940Z",
     "shell.execute_reply": "2022-05-22T20:36:45.772876Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "id": "qRntisqgB-jD",
    "outputId": "0046cc24-ffec-4a25-84fb-fe344a7e78dd",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:20:19.739358Z",
     "iopub.execute_input": "2022-05-22T20:20:19.739638Z",
     "iopub.status.idle": "2022-05-22T20:20:19.817061Z",
     "shell.execute_reply.started": "2022-05-22T20:20:19.739607Z",
     "shell.execute_reply": "2022-05-22T20:20:19.816263Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset_path = \"../input/semeval2018/train_task_a_full_analyzed.txt\"\n",
    "test_dataset_path = \"../input/semeval2018/test_task_a_full_analyzed.txt\""
   ],
   "metadata": {
    "id": "g0o65_84CL1Q",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:20:25.091178Z",
     "iopub.execute_input": "2022-05-22T20:20:25.092104Z",
     "iopub.status.idle": "2022-05-22T20:20:25.096212Z",
     "shell.execute_reply.started": "2022-05-22T20:20:25.092056Z",
     "shell.execute_reply": "2022-05-22T20:20:25.095441Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(train_dataset_path, sep=\"\\t\")\n",
    "test_df = pd.read_csv(test_dataset_path, sep=\"\\t\")\n",
    "train_df, validation_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:20:33.780194Z",
     "iopub.execute_input": "2022-05-22T20:20:33.780447Z",
     "iopub.status.idle": "2022-05-22T20:20:33.810902Z",
     "shell.execute_reply.started": "2022-05-22T20:20:33.780418Z",
     "shell.execute_reply": "2022-05-22T20:20:33.810103Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "value_counts = train_df[\"label\"].value_counts()\n",
    "sns.barplot(value_counts.index, value_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:20:45.968337Z",
     "iopub.execute_input": "2022-05-22T20:20:45.968604Z",
     "iopub.status.idle": "2022-05-22T20:20:46.176284Z",
     "shell.execute_reply.started": "2022-05-22T20:20:45.968575Z",
     "shell.execute_reply": "2022-05-22T20:20:46.175584Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SarcasticSentenceDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len=128):\n",
    "        if len(sentences) != len(labels):\n",
    "            raise ValueError(\"Sentences and labels should have the same number of elements.\")\n",
    "\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        inputs = self.tokenizer(self.sentences[index],\n",
    "                                truncation=True,\n",
    "                                pad_to_max_length=True,\n",
    "                                return_tensors=\"pt\",\n",
    "                                max_length=self.max_len)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)"
   ],
   "metadata": {
    "id": "N6NpDZwDCX36",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:20:53.795712Z",
     "iopub.execute_input": "2022-05-22T20:20:53.796238Z",
     "iopub.status.idle": "2022-05-22T20:20:53.804336Z",
     "shell.execute_reply.started": "2022-05-22T20:20:53.796200Z",
     "shell.execute_reply": "2022-05-22T20:20:53.803600Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", normalization=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:20:58.549140Z",
     "iopub.execute_input": "2022-05-22T20:20:58.549767Z",
     "iopub.status.idle": "2022-05-22T20:21:03.339293Z",
     "shell.execute_reply.started": "2022-05-22T20:20:58.549724Z",
     "shell.execute_reply": "2022-05-22T20:21:03.338557Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = SarcasticSentenceDataset(sentences=train_df[\"text\"].tolist(),\n",
    "                                         labels=train_df[\"label\"].tolist(),\n",
    "                                         tokenizer=tokenizer)\n",
    "\n",
    "validation_dataset = SarcasticSentenceDataset(sentences=validation_df[\"text\"].tolist(),\n",
    "                                         labels=validation_df[\"label\"].tolist(),\n",
    "                                         tokenizer=tokenizer)\n",
    "\n",
    "test_dataset = SarcasticSentenceDataset(sentences=test_df[\"text\"].tolist(),\n",
    "                                        labels=test_df[\"label\"].tolist(),\n",
    "                                        tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:21:06.690528Z",
     "iopub.execute_input": "2022-05-22T20:21:06.690802Z",
     "iopub.status.idle": "2022-05-22T20:21:06.700303Z",
     "shell.execute_reply.started": "2022-05-22T20:21:06.690771Z",
     "shell.execute_reply": "2022-05-22T20:21:06.699375Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:21:15.433952Z",
     "iopub.execute_input": "2022-05-22T20:21:15.434420Z",
     "iopub.status.idle": "2022-05-22T20:21:15.438631Z",
     "shell.execute_reply.started": "2022-05-22T20:21:15.434381Z",
     "shell.execute_reply": "2022-05-22T20:21:15.437904Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "\n",
    "def train(model,\n",
    "          train_loader,\n",
    "          eval_loader,\n",
    "          device,\n",
    "          lr=5e-5,\n",
    "          num_epochs=5):\n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    optimizer, lr_scheduler = setup_optimizer_and_scheduler(model,\n",
    "                                                            lr,\n",
    "                                                            0,\n",
    "                                                            num_training_steps)\n",
    "\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    best_f1 = 0\n",
    "    best_epoch = -1\n",
    "    best_params = copy.deepcopy(model.state_dict())\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        metrics = evaluate(model, eval_loader, device)\n",
    "        print(f\"validation accuracy: {metrics['accuracy']}\\n\"\n",
    "              f\"validation precision: {metrics['precision']}\\n\"\n",
    "              f\"validation recall: {metrics['recall']}\\n\"\n",
    "              f\"validation f1: {metrics['f1']}\\n\")\n",
    "\n",
    "        if metrics[\"f1\"] > best_f1:\n",
    "            best_f1 = metrics[\"f1\"]\n",
    "            best_epoch = epoch\n",
    "            best_params = copy.deepcopy(model.state_dict())\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        print(f\"patience: {patience}\\n\")\n",
    "        if patience == 3:\n",
    "            break\n",
    "\n",
    "    print(f\"best epoch: {best_epoch}\\n\"\n",
    "          f\"best f1: {best_f1}\\n\")\n",
    "\n",
    "    model.load_state_dict(best_params)\n",
    "    return model\n",
    "\n",
    "\n",
    "def setup_optimizer_and_scheduler(model, lr, num_warmup_steps, num_training_steps):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = get_scheduler(name=\"linear\",\n",
    "                              optimizer=optimizer,\n",
    "                              num_warmup_steps=num_warmup_steps,\n",
    "                              num_training_steps=num_training_steps)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "def evaluate(model, eval_loader, device):\n",
    "    model.eval()\n",
    "    labels_list = []\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            _, preds = torch.max(outputs.logits, dim=1, keepdim=False)\n",
    "            labels_list.extend(batch[\"labels\"].cpu().numpy().tolist())\n",
    "            preds_list.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "    return compute_metrics(labels_list, preds_list)\n",
    "\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": confusion_matrix(y_true, y_pred)\n",
    "    }"
   ],
   "metadata": {
    "id": "CctgAwF_Ca3P",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:21:21.285679Z",
     "iopub.execute_input": "2022-05-22T20:21:21.286227Z",
     "iopub.status.idle": "2022-05-22T20:21:21.303671Z",
     "shell.execute_reply.started": "2022-05-22T20:21:21.286187Z",
     "shell.execute_reply": "2022-05-22T20:21:21.302717Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=2).to(device)"
   ],
   "metadata": {
    "id": "w09PJ_ErDEoW",
    "outputId": "1ffa57eb-97c9-4b34-c38d-26471489aced",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:21:30.499175Z",
     "iopub.execute_input": "2022-05-22T20:21:30.499437Z",
     "iopub.status.idle": "2022-05-22T20:22:02.633342Z",
     "shell.execute_reply.started": "2022-05-22T20:21:30.499407Z",
     "shell.execute_reply": "2022-05-22T20:22:02.632601Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = train(model,\n",
    "              train_loader,\n",
    "              validation_loader,\n",
    "              device,\n",
    "              num_epochs=10,\n",
    "              lr=1e-5)"
   ],
   "metadata": {
    "id": "CjgEYmySDHT-",
    "outputId": "8788a248-31d1-48d2-b39c-e41403b2b9d8",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:22:05.429139Z",
     "iopub.execute_input": "2022-05-22T20:22:05.429395Z",
     "iopub.status.idle": "2022-05-22T20:27:01.354838Z",
     "shell.execute_reply.started": "2022-05-22T20:22:05.429367Z",
     "shell.execute_reply": "2022-05-22T20:27:01.353232Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "metrics = evaluate(model, test_loader, device)\n",
    "print(f\"test accuracy: {metrics['accuracy']}\\n\"\n",
    "      f\"test precision: {metrics['precision']}\\n\"\n",
    "      f\"test recall: {metrics['recall']}\\n\"\n",
    "      f\"test f1: {metrics['f1']}\\n\")\n",
    "\n",
    "sns.heatmap(metrics[\"confusion_matrix\"], annot=True, cmap='Blues', fmt=\"d\")"
   ],
   "metadata": {
    "id": "jOrhnWfiDRZF",
    "outputId": "c4928600-ebe5-4559-df10-9a7f4863a316",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:27:28.134514Z",
     "iopub.execute_input": "2022-05-22T20:27:28.134792Z",
     "iopub.status.idle": "2022-05-22T20:27:32.013993Z",
     "shell.execute_reply.started": "2022-05-22T20:27:28.134760Z",
     "shell.execute_reply": "2022-05-22T20:27:32.013279Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import emoji\n",
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "\n",
    "\n",
    "def get_mean_importance_and_prediction(model, tokenizer, df):\n",
    "    model.eval()\n",
    "    cls_explainer = SequenceClassificationExplainer(model, tokenizer)\n",
    "\n",
    "    progress_bar = tqdm(range(len(df)))\n",
    "    \n",
    "    importance = []\n",
    "    predictions = []\n",
    "    for index, row in df.iterrows():\n",
    "        text = row[\"text\"]\n",
    "        emojis = row[\"emojis\"]\n",
    "        \n",
    "        attributions = cls_explainer(text)\n",
    "        predictions.append(cls_explainer.predicted_class_index)\n",
    "    \n",
    "        if not isinstance(emojis, str):\n",
    "            importance.append(np.nan)\n",
    "            continue\n",
    "    \n",
    "        emoji_importance = []\n",
    "        for emoji_tag in [emoji.demojize(e) for e in emojis]:\n",
    "            for (token, token_importance) in attributions:\n",
    "                if emoji_tag == token:\n",
    "                    emoji_importance.append(token_importance)\n",
    "\n",
    "        importance.append(np.mean(emoji_importance))\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    return importance, predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:29:12.858128Z",
     "iopub.execute_input": "2022-05-22T20:29:12.858415Z",
     "iopub.status.idle": "2022-05-22T20:29:12.964673Z",
     "shell.execute_reply.started": "2022-05-22T20:29:12.858385Z",
     "shell.execute_reply": "2022-05-22T20:29:12.963964Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "importance, predictions = get_mean_importance_and_prediction(model, tokenizer, test_df)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-22T20:29:38.068785Z",
     "iopub.execute_input": "2022-05-22T20:29:38.069261Z",
     "iopub.status.idle": "2022-05-22T20:31:52.770003Z",
     "shell.execute_reply.started": "2022-05-22T20:29:38.069225Z",
     "shell.execute_reply": "2022-05-22T20:31:52.769126Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_df[\"emoji_importance\"] = importance\n",
    "test_df[\"predictions\"] = predictions"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-22T20:33:48.506956Z",
     "iopub.execute_input": "2022-05-22T20:33:48.507224Z",
     "iopub.status.idle": "2022-05-22T20:33:48.530088Z",
     "shell.execute_reply.started": "2022-05-22T20:33:48.507196Z",
     "shell.execute_reply": "2022-05-22T20:33:48.529358Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_df.to_csv(\"test_task_a_full_postprocessed_bertweet.txt\", sep=\"\\t\", index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-22T20:43:18.798904Z",
     "iopub.execute_input": "2022-05-22T20:43:18.799768Z",
     "iopub.status.idle": "2022-05-22T20:43:18.816136Z",
     "shell.execute_reply.started": "2022-05-22T20:43:18.799718Z",
     "shell.execute_reply": "2022-05-22T20:43:18.815425Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "\n",
    "cls_explainer = SequenceClassificationExplainer(model, tokenizer)\n",
    "word_attributions = cls_explainer(\"Perfect time to get really sick  ðŸ˜«ðŸ˜·\")\n",
    "cls_explainer.visualize()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:34:41.839021Z",
     "iopub.execute_input": "2022-05-22T20:34:41.840044Z",
     "iopub.status.idle": "2022-05-22T20:34:42.050933Z",
     "shell.execute_reply.started": "2022-05-22T20:34:41.839991Z",
     "shell.execute_reply": "2022-05-22T20:34:42.050254Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sns.regplot(test_df[test_df[\"predictions\"] == 0][\"emoji_sentiment_scores\"], test_df[test_df[\"predictions\"] == 0][\"emoji_importance\"])\n",
    "sns.regplot(test_df[test_df[\"predictions\"] == 1][\"emoji_sentiment_scores\"], test_df[test_df[\"predictions\"] == 1][\"emoji_importance\"])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-22T20:49:44.076460Z",
     "iopub.execute_input": "2022-05-22T20:49:44.077054Z",
     "iopub.status.idle": "2022-05-22T20:49:44.434216Z",
     "shell.execute_reply.started": "2022-05-22T20:49:44.077014Z",
     "shell.execute_reply": "2022-05-22T20:49:44.433531Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), \"bertweet_full.pth\")\n",
    "print(\"model params saved\")"
   ],
   "metadata": {
    "id": "xLybru06DVtn",
    "outputId": "4e6a21fd-372c-4613-e27c-1afb945c11f1",
    "pycharm": {
     "name": "#%%\n"
    },
    "execution": {
     "iopub.status.busy": "2022-05-22T20:34:36.863026Z",
     "iopub.execute_input": "2022-05-22T20:34:36.863320Z",
     "iopub.status.idle": "2022-05-22T20:34:37.859859Z",
     "shell.execute_reply.started": "2022-05-22T20:34:36.863285Z",
     "shell.execute_reply": "2022-05-22T20:34:37.859092Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  }
 ]
}